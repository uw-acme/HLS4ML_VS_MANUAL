{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28045658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1010\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to import the neccessary imports.\n",
    "# Make sure you have the following files in your working directory\n",
    "#        \"inputs.txt\"\n",
    "#        \"relu_bias.txt\"\n",
    "#        \"relu_weights_gru_basic.txt\"\n",
    "#        \"sigmoid_bias.txt\"\n",
    "#        \"sigmoid_weights_gru_basic.txt\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# # input binaries\n",
    "# in_bin_folder = './input_binaries'\n",
    "# if not os.path.exists(in_bin_folder):\n",
    "#     os.makedirs(in_bin_folder)\n",
    "\n",
    "# # relu package sv file folder\n",
    "# relu_pkg_folder = './relu_weights_biases_pkgs'\n",
    "# if not os.path.exists(relu_pkg_folder):\n",
    "#     os.makedirs(relu_pkg_folder)\n",
    "\n",
    "# # sigmoid package sv file folder\n",
    "# sig_pkg_folder = './sigmoid_weights_biases_pkgs'\n",
    "# if not os.path.exists(sig_pkg_folder):\n",
    "#     os.makedirs(sig_pkg_folder)\n",
    "\n",
    "\n",
    "# # gru package sv file folder\n",
    "gru_pkg_folder = './gru_basic_weights/gru_weights_biases_pkgs'\n",
    "if not os.path.exists(gru_pkg_folder):\n",
    "    os.makedirs(gru_pkg_folder)\n",
    "\n",
    "# # binary that goes to tanh bram/look up table\n",
    "if not os.path.exists('./binaries/tanh_BRAM_binaries'):\n",
    "    os.makedirs('./tanh_BRAM_binaries')\n",
    "\n",
    "# # dense 1 package sv file folder\n",
    "dense_1_pkg_folder = './weights/dense_1_weights_biases_pkgs'\n",
    "if not os.path.exists(dense_1_pkg_folder):\n",
    "    os.makedirs(dense_1_pkg_folder)\n",
    "\n",
    "def flip_bits(val, bits):\n",
    "    return ((val ^ (2**bits - 1)) + 1)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+(np.e**(-x)))\n",
    "\n",
    "# really innefficient but calling \"sed\" subprocess didn't work\n",
    "# Removes negative sign \"-\" from file\n",
    "def remove_negs(tmp_file, dest_file_name):\n",
    "    output_file = open(tmp_file, 'r')\n",
    "    dest_file = open(dest_file_name, 'w')\n",
    "    file = output_file.read()\n",
    "    file = file.replace('b-', 'b')\n",
    "    dest_file.write(file)\n",
    "    # close files\n",
    "    dest_file.close()\n",
    "    output_file.close()\n",
    "    \n",
    "# =========================================================================\n",
    "# pkg functions (for sub-processes)\n",
    "# =========================================================================\n",
    "def get_pkg_name(name, width, nfrac):\n",
    "    return str(name) + '_' + str(width) + '_' + str(width - nfrac)\n",
    "\n",
    "def conv_to_str(num, width, nfrac):\n",
    "\n",
    "    # shift the decimal point to the right\n",
    "    div = (2**nfrac)*1.0\n",
    "    x = round(float(num * div // 1))\n",
    "\n",
    "    if (x < 0):\n",
    "        return format(flip_bits(x, width), '0'+ str(width) + 'b')\n",
    "    return format(x, '0'+ str(width) + 'b')\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "\n",
    "# print(conv_to_str(4.127311706542969, 4, 2))\n",
    "print(conv_to_str(-1.5, 4, 2))\n",
    "# print(conv_to_str(-2.344774007797241, 10, 5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "659e1cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 15:17:49.331279: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-08 15:17:50.553404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-08 15:17:50.566563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-08 15:17:50.566629: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-08 15:17:50.567015: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-08 15:17:50.568679: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, 120)               46080     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,443\n",
      "Trainable params: 46,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-08 15:17:50.568756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-08 15:17:50.568810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-08 15:17:50.660207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-08 15:17:50.660319: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-08 15:17:50.660331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-08 15:17:50.660392: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-08 15:17:50.660425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13687 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('../../../../documents/Benchmarks/RNN/ftag/gru_model/gru_basic.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccbc1f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru_1\n",
      "{'name': 'gru_1', 'trainable': True, 'dtype': 'float32', 'batch_input_shape': (None, 2, 6), 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'time_major': False, 'units': 120, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2, 'reset_after': True}\n",
      "Number of weights tensors: 3\n",
      "input size 6\n",
      "hidden state size 120\n",
      "reset_gate_weight\n",
      "(126, 120)\n",
      "update_gate_weight\n",
      "(126, 120)\n",
      "candidate_gate_weight\n",
      "(126, 120)\n",
      "reset_gate_bias\n",
      "(120,)\n",
      "update_gate_bias\n",
      "(120,)\n",
      "candidate_gate_bias\n",
      "(120,)\n",
      "max and min values\n",
      "reset_gate_weight\n",
      "0.20108204\n",
      "-0.1985999\n",
      "update_gate_weight\n",
      "0.20069064\n",
      "-0.20899363\n",
      "candidate_gate_weight\n",
      "0.2034\n",
      "-0.19430716\n",
      "reset_gate_bias\n",
      "0.0\n",
      "0.0\n",
      "update_gate_bias\n",
      "0.0\n",
      "0.0\n",
      "candidate_gate_bias\n",
      "0.0\n",
      "0.0\n",
      "=====================================================================================================\n",
      "dense_1\n",
      "{'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "weights shape\n",
      "(120, 3)\n",
      "biases shape\n",
      "(3,)\n",
      "max and min values\n",
      "weights\n",
      "0.21828283\n",
      "-0.22005482\n",
      "biases\n",
      "0.0\n",
      "0.0\n",
      "=====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Extract weights and biases for each layer (gru layer separated to 3 dense) and print the weights to output and to files with name layer_weight.txt and layer_bias.txt\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n",
    "    if layer.name == 'gru_1':\n",
    "\n",
    "        print(layer.get_config())\n",
    "\n",
    "        weights = layer.get_weights()\n",
    "        print(\"Number of weights tensors: \" + str(len(weights)))\n",
    "\n",
    "        # W for x, U for h, B for biases\n",
    "        W = weights[0]\n",
    "        U = weights[1]\n",
    "        B = weights[2]\n",
    "\n",
    "        print(\"input size \" + str(W.shape[0]))\n",
    "        print(\"hidden state size \" + str(layer.units))\n",
    "\n",
    "        # extract three weights and biases for the three dense layers\n",
    "\n",
    "        reset_gate_weight = np.concatenate((W[:, :layer.units], U[:, :layer.units]), axis = 0)\n",
    "        update_gate_weight = np.concatenate((W[:, layer.units:2*layer.units], U[:, layer.units:2*layer.units]), axis=0)\n",
    "        candidate_gate_weight = np.concatenate((W[:, 2*layer.units:], U[:, 2*layer.units:]), axis=0)\n",
    "\n",
    "        # combine input biases and recurrent biases\n",
    "        # notice recurrent biases is used when reset_after config set to True for the gru layer (default is True)\n",
    "        reset_gate_bias = np.sum(B[:, :layer.units], axis = 0)\n",
    "        update_gate_bias = np.sum(B[:, layer.units:2*layer.units], axis = 0)\n",
    "        candidate_gate_bias = np.sum(B[:, 2*layer.units:], axis = 0)\n",
    "\n",
    "        print(\"reset_gate_weight\")\n",
    "        print(reset_gate_weight.shape)\n",
    "        print(\"update_gate_weight\")\n",
    "        print(update_gate_weight.shape)\n",
    "        print(\"candidate_gate_weight\")\n",
    "        print(candidate_gate_weight.shape)\n",
    "\n",
    "        print(\"reset_gate_bias\")\n",
    "        print(reset_gate_bias.shape)\n",
    "        print(\"update_gate_bias\")\n",
    "        print(update_gate_bias.shape)\n",
    "        print(\"candidate_gate_bias\")\n",
    "        print(candidate_gate_bias.shape)\n",
    "\n",
    "\n",
    "        # find maximum and minimum values for each weight and bias\n",
    "        print(\"max and min values\")\n",
    "        print(\"reset_gate_weight\")\n",
    "        print(np.max(reset_gate_weight))\n",
    "        print(np.min(reset_gate_weight))\n",
    "        print(\"update_gate_weight\")\n",
    "        print(np.max(update_gate_weight))\n",
    "        print(np.min(update_gate_weight))\n",
    "        print(\"candidate_gate_weight\")\n",
    "        print(np.max(candidate_gate_weight))\n",
    "        print(np.min(candidate_gate_weight))\n",
    "\n",
    "        print(\"reset_gate_bias\")\n",
    "        print(np.max(reset_gate_bias))\n",
    "        print(np.min(reset_gate_bias))\n",
    "        print(\"update_gate_bias\")\n",
    "        print(np.max(update_gate_bias))\n",
    "        print(np.min(update_gate_bias))\n",
    "        print(\"candidate_gate_bias\")\n",
    "        print(np.max(candidate_gate_bias))\n",
    "        print(np.min(candidate_gate_bias))\n",
    "        \n",
    "\n",
    "        # write to npy files\n",
    "        np.savetxt('reset_gate_weights_gru_basic.txt', reset_gate_weight.flatten())\n",
    "        np.savetxt('update_gate_weights_gru_basic.txt', update_gate_weight.flatten())\n",
    "        np.savetxt('candidate_gate_weights_gru_basic.txt', candidate_gate_weight.flatten())\n",
    "\n",
    "        np.savetxt('reset_gate_biases_gru_basic.txt', reset_gate_bias.flatten())\n",
    "        np.savetxt('update_gate_biases_gru_basic.txt', update_gate_bias.flatten())\n",
    "        np.savetxt('candidate_gate_biases_gru_basic.txt', candidate_gate_bias.flatten())\n",
    "\n",
    "\n",
    "    elif layer.name != \"input_1\":\n",
    "        # all other layers are dense with relu activation\n",
    "        \n",
    "        # print layer info (activation)\n",
    "        print(layer.get_config())\n",
    "        dense_weights = layer.get_weights()\n",
    "        weights = dense_weights[0]\n",
    "        biases = dense_weights[1]\n",
    "\n",
    "        # print weights and biases\n",
    "        print(\"weights shape\")\n",
    "        print(weights.shape)\n",
    "        print(\"biases shape\")\n",
    "        print(biases.shape)\n",
    "\n",
    "        # find maximum and minimum values for each weight and bias\n",
    "        print(\"max and min values\")\n",
    "        print(\"weights\")\n",
    "        print(np.max(weights))\n",
    "        print(np.min(weights))\n",
    "        print(\"biases\")\n",
    "        print(np.max(biases))\n",
    "        print(np.min(biases))    \n",
    "\n",
    "        # # write to a txt file, flatten the weights\n",
    "        np.savetxt(layer.name + '_weights_gru_basic.txt', weights.flatten())\n",
    "        np.savetxt(layer.name + '_biases_gru_basic.txt', biases.flatten())\n",
    "    \n",
    "    print(\"=====================================================================================================\")\n",
    "\n",
    "\n",
    "# ALter this to reflect state of files\n",
    "NUM_INPUTS = 10\n",
    "\n",
    "INPUT_SIZE_DENSE_0 = 120\n",
    "OUTPUT_SIZE_DENSE_0 = 50\n",
    "\n",
    "INPUT_SIZE_DENSE_1 = 120\n",
    "OUTPUT_SIZE_DENSE_1 = 3\n",
    "\n",
    "INPUT_SIZE_OUT_DENSE = 10\n",
    "OUTPUT_SIZE_OUT_DENSE = 3\n",
    "\n",
    "INPUT_SIZE_GRU = 6\n",
    "OUTPUT_SIZE_GRU = 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc6940da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# generate dense wights and bias package\n",
    "# =======================================================\n",
    "\n",
    "def generate_dense_pkg_file(name, dest_folder, width, nfrac, weights_file, biases_file, input_size, output_size):\n",
    "# arguments:\n",
    "# name: name of the layer\n",
    "# width: width of the binary\n",
    "# nfrac: number of fractional bits\n",
    "# weights_file: file containing weights\n",
    "# biases_file: file containing biases\n",
    "# num_weights: number of weights\n",
    "# num_biases: number of biases\n",
    "    \n",
    "    # determine the maximum and minimum values the fix point number can represent\n",
    "    max_val = (2**(width-1) - 1)/(2**nfrac)\n",
    "    min_val = -2**(width-1)/(2**nfrac)\n",
    "    print(\"Max value: \" + str(max_val))\n",
    "    print(\"Min value: \" + str(min_val))\n",
    "\n",
    "    # open source files\n",
    "    src_weights_file = open(weights_file, 'r')\n",
    "    src_biases_file = open(biases_file, 'r')\n",
    "    \n",
    "    package_name = get_pkg_name(name, width, nfrac)\n",
    "\n",
    "    # make the final output files\n",
    "    file_name = dest_folder + package_name + \".sv\"\n",
    "    dest_file = open(file_name, 'w')\n",
    "\n",
    "    print(package_name)\n",
    "\n",
    "    # first decalaration lines\n",
    "    dest_file.write(\"// Width: \" + str(width) + \"\\n// NFRAC: \" + str(nfrac) + \"\\n\")\n",
    "    dest_file.write(\"package \" + str(package_name) + ';\\n\\n')\n",
    "    dest_file.write(f\"localparam logic signed [{str(width-1)}:0] weights [{str(input_size)}][{str(output_size)}] = \\'{{ \\n\")\n",
    "\n",
    "    # convert weights (from floats) into binary\n",
    "    for i in range(input_size):\n",
    "        dest_file.write(\"{\")\n",
    "        for j in range(output_size):\n",
    "            flt_num = float(src_weights_file.readline())\n",
    "                        \n",
    "            if (flt_num > max_val):\n",
    "                flt_num = max_val\n",
    "            elif (flt_num < min_val):\n",
    "                flt_num = min_val\n",
    "\n",
    "            binary_num = conv_to_str(flt_num, width, nfrac).replace('-', '')\n",
    "\n",
    "            # Overflow checking, now handled by converting extreme values to max/min values\n",
    "            if (len(binary_num) < width):\n",
    "                print(\"ERROR: binary number too large\")\n",
    "                print(\"binary number: \" + binary_num)\n",
    "                print(\"float number: \" + str(flt_num))\n",
    "                print(\"width: \" + str(width))\n",
    "                print(\"binary number length: \" + str(len(binary_num)))\n",
    "                print(\"from file: \" + weights_file)\n",
    "                raise ValueError(\"Binary number width inconsistent\")\n",
    "\n",
    "\n",
    "            dest_file.write(str(width) + \"\\'b\" + binary_num)\n",
    "            if (j != output_size - 1):\n",
    "                dest_file.write(\", \")\n",
    "            else:\n",
    "                dest_file.write(\"}\")\n",
    "\n",
    "        if (i != (input_size-1)): # no comma for last term\n",
    "            # OPTIONAL: adds floating number as comment as reference\n",
    "            dest_file.write(\", \" + \"\\n\")\n",
    "        else:\n",
    "            dest_file.write(\"\\n\")                \n",
    "    \n",
    "    # switch to declaring biases\n",
    "    dest_file.write(\"};\\n\\n\")\n",
    "    dest_file.write(\"localparam logic signed [\"+ str(width-1) + \":0] bias [\" + str(output_size) + \"] = \\'{\\n\")\n",
    "    \n",
    "    # convert bias (from floats) into binary\n",
    "    for i in range(output_size):\n",
    "        flt_num = float(src_biases_file.readline())\n",
    "        \n",
    "        # e.g. write line \"17'b01011011011111001,\"\n",
    "        dest_file.write(str(width) + \"\\'b\" + conv_to_str(flt_num, width, nfrac).replace('-', ''))\n",
    "        \n",
    "        if (i != (output_size-1)): # no comma for last term\n",
    "            # OPTIONAL: adds floating number as comment as reference\n",
    "            dest_file.write(\",  // \" + str(flt_num) + \"\\n\")\n",
    "        else:\n",
    "            dest_file.write(\"   // \" + str(flt_num) + \"\\n\")\n",
    "        \n",
    "        \n",
    "    # finish off declarations\n",
    "    dest_file.write(\"};\\nendpackage\")\n",
    "    \n",
    "    \n",
    "    dest_file.close()\n",
    "    src_biases_file.close()\n",
    "    src_weights_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d58b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gru_pkg_file(width, nfrac, input_size, output_size):\n",
    "\n",
    "    # input size for each gru internal gate is input_size + h, which is input_size + output_size\n",
    "    generate_dense_pkg_file(\"candidate_gate\", \"./gru_basic_weights/gru_weights_biases_pkgs/candidate_gate_weights_biases_pkgs/\", width, nfrac, \"candidate_gate_weights_gru_basic.txt\", \"candidate_gate_biases_gru_basic.txt\", input_size + output_size, output_size)\n",
    "    generate_dense_pkg_file(\"reset_gate\", \"./gru_basic_weights/gru_weights_biases_pkgs/reset_gate_weights_biases_pkgs/\", width, nfrac, \"reset_gate_weights_gru_basic.txt\", \"reset_gate_biases_gru_basic.txt\", input_size + output_size, output_size)\n",
    "    generate_dense_pkg_file(\"update_gate\", \"./gru_basic_weights/gru_weights_biases_pkgs/update_gate_weights_biases_pkgs/\", width, nfrac, \"update_gate_weights_gru_basic.txt\", \"update_gate_biases_gru_basic.txt\", input_size + output_size, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c11f63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =======================================================\n",
    "# # generate input vals\n",
    "# # =======================================================\n",
    "\n",
    "# def generate_input_bin_file(width, nfrac):\n",
    "#     div = (2**nfrac)*1.0\n",
    "\n",
    "#     src_file = open(\"inputs.txt\", 'r')\n",
    "    \n",
    "#     file_name = in_bin_folder + \"/bw\" + str(width) + \"_nfrac\" + str(nfrac) + \"_inputs.mem\"\n",
    "#     tmp_file = in_bin_folder + \"/tmp\"\n",
    "#     dest_file = open(tmp_file, 'w')\n",
    "\n",
    "\n",
    "#     for i in range(NUM_INPUTS):\n",
    "#         x = float(src_file.readline())\n",
    "#         dest_file.write(conv_to_str(x, width, nfrac))\n",
    "#         dest_file.write(\"\\n\")\n",
    "    \n",
    "#     #subprocess.call([\"sed\", 's/-//g', file_name]) # doesn't work\n",
    "#     dest_file.close()\n",
    "#     src_file.close()\n",
    "    \n",
    "#     # replace negative '-' character\n",
    "#     remove_negs(tmp_file, file_name)\n",
    "\n",
    "# # =+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=\n",
    "\n",
    "# # Set width and fractional bits you want to generate\n",
    "# width = 10\n",
    "# nfrac = 5\n",
    "\n",
    "# # run function\n",
    "# # generate_input_bin_file(width, nfrac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cfd29a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: 1.75\n",
      "Min value: -2.0\n",
      "dense_1_4_2\n",
      "Max value: 1.75\n",
      "Min value: -2.0\n",
      "candidate_gate_4_2\n",
      "Max value: 1.75\n",
      "Min value: -2.0\n",
      "reset_gate_4_2\n",
      "Max value: 1.75\n",
      "Min value: -2.0\n",
      "update_gate_4_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: 1.875\n",
      "Min value: -2.0\n",
      "dense_1_5_2\n",
      "Max value: 1.875\n",
      "Min value: -2.0\n",
      "candidate_gate_5_2\n",
      "Max value: 1.875\n",
      "Min value: -2.0\n",
      "reset_gate_5_2\n",
      "Max value: 1.875\n",
      "Min value: -2.0\n",
      "update_gate_5_2\n",
      "Max value: 3.875\n",
      "Min value: -4.0\n",
      "dense_1_6_3\n",
      "Max value: 3.875\n",
      "Min value: -4.0\n",
      "candidate_gate_6_3\n",
      "Max value: 3.875\n",
      "Min value: -4.0\n",
      "reset_gate_6_3\n",
      "Max value: 3.875\n",
      "Min value: -4.0\n",
      "update_gate_6_3\n",
      "Max value: 3.9375\n",
      "Min value: -4.0\n",
      "dense_1_7_3\n",
      "Max value: 3.9375\n",
      "Min value: -4.0\n",
      "candidate_gate_7_3\n",
      "Max value: 3.9375\n",
      "Min value: -4.0\n",
      "reset_gate_7_3\n",
      "Max value: 3.9375\n",
      "Min value: -4.0\n",
      "update_gate_7_3\n",
      "Max value: 7.9375\n",
      "Min value: -8.0\n",
      "dense_1_8_4\n",
      "Max value: 7.9375\n",
      "Min value: -8.0\n",
      "candidate_gate_8_4\n",
      "Max value: 7.9375\n",
      "Min value: -8.0\n",
      "reset_gate_8_4\n",
      "Max value: 7.9375\n",
      "Min value: -8.0\n",
      "update_gate_8_4\n",
      "Max value: 7.96875\n",
      "Min value: -8.0\n",
      "dense_1_9_4\n",
      "Max value: 7.96875\n",
      "Min value: -8.0\n",
      "candidate_gate_9_4\n",
      "Max value: 7.96875\n",
      "Min value: -8.0\n",
      "reset_gate_9_4\n",
      "Max value: 7.96875\n",
      "Min value: -8.0\n",
      "update_gate_9_4\n",
      "Max value: 15.96875\n",
      "Min value: -16.0\n",
      "dense_1_10_5\n",
      "Max value: 15.96875\n",
      "Min value: -16.0\n",
      "candidate_gate_10_5\n",
      "Max value: 15.96875\n",
      "Min value: -16.0\n",
      "reset_gate_10_5\n",
      "Max value: 15.96875\n",
      "Min value: -16.0\n",
      "update_gate_10_5\n",
      "Max value: 15.984375\n",
      "Min value: -16.0\n",
      "dense_1_11_5\n",
      "Max value: 15.984375\n",
      "Min value: -16.0\n",
      "candidate_gate_11_5\n",
      "Max value: 15.984375\n",
      "Min value: -16.0\n",
      "reset_gate_11_5\n",
      "Max value: 15.984375\n",
      "Min value: -16.0\n",
      "update_gate_11_5\n",
      "Max value: 31.984375\n",
      "Min value: -32.0\n",
      "dense_1_12_6\n",
      "Max value: 31.984375\n",
      "Min value: -32.0\n",
      "candidate_gate_12_6\n",
      "Max value: 31.984375\n",
      "Min value: -32.0\n",
      "reset_gate_12_6\n",
      "Max value: 31.984375\n",
      "Min value: -32.0\n",
      "update_gate_12_6\n",
      "Max value: 31.9921875\n",
      "Min value: -32.0\n",
      "dense_1_13_6\n",
      "Max value: 31.9921875\n",
      "Min value: -32.0\n",
      "candidate_gate_13_6\n",
      "Max value: 31.9921875\n",
      "Min value: -32.0\n",
      "reset_gate_13_6\n",
      "Max value: 31.9921875\n",
      "Min value: -32.0\n",
      "update_gate_13_6\n",
      "Max value: 63.9921875\n",
      "Min value: -64.0\n",
      "dense_1_14_7\n",
      "Max value: 63.9921875\n",
      "Min value: -64.0\n",
      "candidate_gate_14_7\n",
      "Max value: 63.9921875\n",
      "Min value: -64.0\n",
      "reset_gate_14_7\n",
      "Max value: 63.9921875\n",
      "Min value: -64.0\n",
      "update_gate_14_7\n",
      "Max value: 63.99609375\n",
      "Min value: -64.0\n",
      "dense_1_15_7\n",
      "Max value: 63.99609375\n",
      "Min value: -64.0\n",
      "candidate_gate_15_7\n",
      "Max value: 63.99609375\n",
      "Min value: -64.0\n",
      "reset_gate_15_7\n",
      "Max value: 63.99609375\n",
      "Min value: -64.0\n",
      "update_gate_15_7\n",
      "Max value: 127.99609375\n",
      "Min value: -128.0\n",
      "dense_1_16_8\n",
      "Max value: 127.99609375\n",
      "Min value: -128.0\n",
      "candidate_gate_16_8\n",
      "Max value: 127.99609375\n",
      "Min value: -128.0\n",
      "reset_gate_16_8\n",
      "Max value: 127.99609375\n",
      "Min value: -128.0\n",
      "update_gate_16_8\n",
      "Max value: 127.998046875\n",
      "Min value: -128.0\n",
      "dense_1_17_8\n",
      "Max value: 127.998046875\n",
      "Min value: -128.0\n",
      "candidate_gate_17_8\n",
      "Max value: 127.998046875\n",
      "Min value: -128.0\n",
      "reset_gate_17_8\n",
      "Max value: 127.998046875\n",
      "Min value: -128.0\n",
      "update_gate_17_8\n",
      "Max value: 255.998046875\n",
      "Min value: -256.0\n",
      "dense_1_18_9\n",
      "Max value: 255.998046875\n",
      "Min value: -256.0\n",
      "candidate_gate_18_9\n",
      "Max value: 255.998046875\n",
      "Min value: -256.0\n",
      "reset_gate_18_9\n",
      "Max value: 255.998046875\n",
      "Min value: -256.0\n",
      "update_gate_18_9\n",
      "Max value: 255.9990234375\n",
      "Min value: -256.0\n",
      "dense_1_19_9\n",
      "Max value: 255.9990234375\n",
      "Min value: -256.0\n",
      "candidate_gate_19_9\n",
      "Max value: 255.9990234375\n",
      "Min value: -256.0\n",
      "reset_gate_19_9\n",
      "Max value: 255.9990234375\n",
      "Min value: -256.0\n",
      "update_gate_19_9\n",
      "Max value: 511.9990234375\n",
      "Min value: -512.0\n",
      "dense_1_20_10\n",
      "Max value: 511.9990234375\n",
      "Min value: -512.0\n",
      "candidate_gate_20_10\n",
      "Max value: 511.9990234375\n",
      "Min value: -512.0\n",
      "reset_gate_20_10\n",
      "Max value: 511.9990234375\n",
      "Min value: -512.0\n",
      "update_gate_20_10\n",
      "Max value: 511.99951171875\n",
      "Min value: -512.0\n",
      "dense_1_21_10\n",
      "Max value: 511.99951171875\n",
      "Min value: -512.0\n",
      "candidate_gate_21_10\n",
      "Max value: 511.99951171875\n",
      "Min value: -512.0\n",
      "reset_gate_21_10\n",
      "Max value: 511.99951171875\n",
      "Min value: -512.0\n",
      "update_gate_21_10\n",
      "Max value: 1023.99951171875\n",
      "Min value: -1024.0\n",
      "dense_1_22_11\n",
      "Max value: 1023.99951171875\n",
      "Min value: -1024.0\n",
      "candidate_gate_22_11\n",
      "Max value: 1023.99951171875\n",
      "Min value: -1024.0\n",
      "reset_gate_22_11\n",
      "Max value: 1023.99951171875\n",
      "Min value: -1024.0\n",
      "update_gate_22_11\n",
      "Max value: 1023.999755859375\n",
      "Min value: -1024.0\n",
      "dense_1_23_11\n",
      "Max value: 1023.999755859375\n",
      "Min value: -1024.0\n",
      "candidate_gate_23_11\n",
      "Max value: 1023.999755859375\n",
      "Min value: -1024.0\n",
      "reset_gate_23_11\n",
      "Max value: 1023.999755859375\n",
      "Min value: -1024.0\n",
      "update_gate_23_11\n",
      "Max value: 2047.999755859375\n",
      "Min value: -2048.0\n",
      "dense_1_24_12\n",
      "Max value: 2047.999755859375\n",
      "Min value: -2048.0\n",
      "candidate_gate_24_12\n",
      "Max value: 2047.999755859375\n",
      "Min value: -2048.0\n",
      "reset_gate_24_12\n",
      "Max value: 2047.999755859375\n",
      "Min value: -2048.0\n",
      "update_gate_24_12\n",
      "Max value: 2047.9998779296875\n",
      "Min value: -2048.0\n",
      "dense_1_25_12\n",
      "Max value: 2047.9998779296875\n",
      "Min value: -2048.0\n",
      "candidate_gate_25_12\n",
      "Max value: 2047.9998779296875\n",
      "Min value: -2048.0\n",
      "reset_gate_25_12\n",
      "Max value: 2047.9998779296875\n",
      "Min value: -2048.0\n",
      "update_gate_25_12\n",
      "Max value: 4095.9998779296875\n",
      "Min value: -4096.0\n",
      "dense_1_26_13\n",
      "Max value: 4095.9998779296875\n",
      "Min value: -4096.0\n",
      "candidate_gate_26_13\n",
      "Max value: 4095.9998779296875\n",
      "Min value: -4096.0\n",
      "reset_gate_26_13\n",
      "Max value: 4095.9998779296875\n",
      "Min value: -4096.0\n",
      "update_gate_26_13\n",
      "Max value: 4095.9999389648438\n",
      "Min value: -4096.0\n",
      "dense_1_27_13\n",
      "Max value: 4095.9999389648438\n",
      "Min value: -4096.0\n",
      "candidate_gate_27_13\n",
      "Max value: 4095.9999389648438\n",
      "Min value: -4096.0\n",
      "reset_gate_27_13\n",
      "Max value: 4095.9999389648438\n",
      "Min value: -4096.0\n",
      "update_gate_27_13\n",
      "Max value: 8191.999938964844\n",
      "Min value: -8192.0\n",
      "dense_1_28_14\n",
      "Max value: 8191.999938964844\n",
      "Min value: -8192.0\n",
      "candidate_gate_28_14\n",
      "Max value: 8191.999938964844\n",
      "Min value: -8192.0\n",
      "reset_gate_28_14\n",
      "Max value: 8191.999938964844\n",
      "Min value: -8192.0\n",
      "update_gate_28_14\n",
      "Max value: 8191.999969482422\n",
      "Min value: -8192.0\n",
      "dense_1_29_14\n",
      "Max value: 8191.999969482422\n",
      "Min value: -8192.0\n",
      "candidate_gate_29_14\n",
      "Max value: 8191.999969482422\n",
      "Min value: -8192.0\n",
      "reset_gate_29_14\n",
      "Max value: 8191.999969482422\n",
      "Min value: -8192.0\n",
      "update_gate_29_14\n",
      "Max value: 16383.999969482422\n",
      "Min value: -16384.0\n",
      "dense_1_30_15\n",
      "Max value: 16383.999969482422\n",
      "Min value: -16384.0\n",
      "candidate_gate_30_15\n",
      "Max value: 16383.999969482422\n",
      "Min value: -16384.0\n",
      "reset_gate_30_15\n",
      "Max value: 16383.999969482422\n",
      "Min value: -16384.0\n",
      "update_gate_30_15\n",
      "Max value: 16383.999984741211\n",
      "Min value: -16384.0\n",
      "dense_1_31_15\n",
      "Max value: 16383.999984741211\n",
      "Min value: -16384.0\n",
      "candidate_gate_31_15\n",
      "Max value: 16383.999984741211\n",
      "Min value: -16384.0\n",
      "reset_gate_31_15\n",
      "Max value: 16383.999984741211\n",
      "Min value: -16384.0\n",
      "update_gate_31_15\n",
      "Max value: 32767.99998474121\n",
      "Min value: -32768.0\n",
      "dense_1_32_16\n",
      "Max value: 32767.99998474121\n",
      "Min value: -32768.0\n",
      "candidate_gate_32_16\n",
      "Max value: 32767.99998474121\n",
      "Min value: -32768.0\n",
      "reset_gate_32_16\n",
      "Max value: 32767.99998474121\n",
      "Min value: -32768.0\n",
      "update_gate_32_16\n"
     ]
    }
   ],
   "source": [
    "# Weight generating file specific to ftag model.\n",
    "\n",
    "# # Set width and fractional bits you want to generate\n",
    "# width = 10\n",
    "# nfrac = 5\n",
    "\n",
    "# # run function\n",
    "# generate_dense_pkg_file(\"dense_0\", width, nfrac, \"dense_0_weights_gru_basic.txt\", \"dense_0_biases_gru_basic.txt\", NUM_WEIGHTS_DENSE_0, NUM_BIAS_DENSE_0)\n",
    "# generate_dense_pkg_file(\"dense_1\", width, nfrac, \"dense_1_weights_gru_basic.txt\", \"dense_1_biases_gru_basic.txt\", NUM_WEIGHTS_DENSE_1, NUM_BIAS_DENSE_1)\n",
    "\n",
    "# generate set of files for bit width 4-32\n",
    "for i in range(4,33):\n",
    "    width = i\n",
    "    nfrac = (i+1) // 2\n",
    "    \n",
    "    # generate_input_bin_file(width, nfrac)\n",
    "    # generate_dense_pkg_file(\"dense_0\", \"./gru_basic_weights/dense_0_weights_biases_pkgs/\", width, nfrac, \"dense_0_weights_gru_basic.txt\", \"dense_0_biases_gru_basic.txt\", INPUT_SIZE_DENSE_0, OUTPUT_SIZE_DENSE_0)\n",
    "    generate_dense_pkg_file(\"dense_1\", \"./gru_basic_weights/dense_1_weights_biases_pkgs/\", width, nfrac, \"dense_1_weights_gru_basic.txt\", \"dense_1_biases_gru_basic.txt\", INPUT_SIZE_DENSE_1, OUTPUT_SIZE_DENSE_1)\n",
    "    generate_gru_pkg_file(width, nfrac, INPUT_SIZE_GRU, OUTPUT_SIZE_GRU)\n",
    "    # output layer\n",
    "    # generate_dense_pkg_file(\"output\", \"./gru_basic_weights/output_weights_biases_pkgs/\", width, nfrac, \"output_softmax_weights_gru_basic.txt\", \"output_softmax_biases_gru_basic.txt\", INPUT_SIZE_OUT_DENSE, OUTPUT_SIZE_OUT_DENSE)\n",
    "\n",
    "# width = 16\n",
    "# nfrac = 10\n",
    "# generate_gru_pkg_file(width, nfrac, INPUT_SIZE_GRU, OUTPUT_SIZE_GRU)\n",
    "# generate_dense_pkg_file(\"dense_0\", \"./weights/dense_0_weights_biases_pkgs/\", width, nfrac, \"dense_0_weights_gru_basic.txt\", \"dense_0_biases_gru_basic.txt\", INPUT_SIZE_DENSE_0, OUTPUT_SIZE_DENSE_0)\n",
    "# generate_dense_pkg_file(\"dense_1\", \"./weights/dense_1_weights_biases_pkgs/\", width, nfrac, \"dense_1_weights_gru_basic.txt\", \"dense_1_biases_gru_basic.txt\", INPUT_SIZE_DENSE_1, OUTPUT_SIZE_DENSE_1)\n",
    "# # output layer\n",
    "# generate_dense_pkg_file(\"output\", \"./weights/output_weights_biases_pkgs/\", width, nfrac, \"output_softmax_weights_gru_basic.txt\", \"output_softmax_biases_gru_basic.txt\", INPUT_SIZE_OUT_DENSE, OUTPUT_SIZE_OUT_DENSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26d5b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =======================================================\n",
    "# # generate sigmoid wights and bias package\n",
    "# # =======================================================\n",
    "\n",
    "\n",
    "# def generate_sigmoid_pkg_file(width, nfrac):\n",
    "#     # open source files\n",
    "#     src_weights_file = open(\"sigmoid_weights_gru_basic.txt\", 'r')\n",
    "#     src_biases_file = open(\"sigmoid_bias.txt\", 'r')\n",
    "    \n",
    "#     # make the final output files\n",
    "#     file_name = sig_pkg_folder + \"/\" + get_pkg_name(\"sigmoid\", width, nfrac) + \".sv\"\n",
    "#     tmp_file = sig_pkg_folder + \"/tmp\"\n",
    "#     dest_file = open(tmp_file, 'w') # write to tmp file, will write to final when cleaning up '-' signs\n",
    "\n",
    "#     # first decalaration lines\n",
    "#     dest_file.write(\"// Width: \" + str(width) + \"\\n// NFRAC: \" + str(nfrac) + \"\\n\")\n",
    "#     dest_file.write(\"package \" + str(get_pkg_name(\"sigmoid\", width, nfrac)) + ';\\n\\n')\n",
    "#     dest_file.write(\"localparam logic signed [\"+ str(width-1) + \":0] weights [\" + str(NUM_WEIGHTS_SIGMOID) + \"] = \\'{\\n\")\n",
    "\n",
    "#     # convert weights (from floats) into binary\n",
    "#     for i in range(NUM_WEIGHTS_SIGMOID):\n",
    "#         flt_num = float(src_weights_file.readline())\n",
    "        \n",
    "#         # e.g. write line \"17'b01011011011111001,\"\n",
    "#         dest_file.write(str(width) + \"\\'b\" + conv_to_str(flt_num, width, nfrac))\n",
    "        \n",
    "#         if (i != (NUM_WEIGHTS_SIGMOID-1)): # no comma for last term\n",
    "#             # OPTIONAL: adds floating number as comment as reference\n",
    "#             dest_file.write(\",  // \" + str(flt_num) + \"\\n\")\n",
    "#         else:\n",
    "#             dest_file.write(\"   // \" + str(flt_num) + \"\\n\")\n",
    "    \n",
    "#     # switch to declaring biases\n",
    "#     dest_file.write(\"};\\n\\n\")\n",
    "#     dest_file.write(\"localparam logic signed [\"+ str(width-1) + \":0] bias [\" + str(NUM_BIAS_SIGMOID) + \"] = \\'{\\n\")\n",
    "    \n",
    "#     # convert bias (from floats) into binary\n",
    "#     for i in range(NUM_BIAS_SIGMOID):\n",
    "#         flt_num = float(src_biases_file.readline())\n",
    "        \n",
    "#         # e.g. write line \"17'b01011011011111001,\"\n",
    "#         dest_file.write(str(width) + \"\\'b\" + conv_to_str(flt_num, width, nfrac))\n",
    "        \n",
    "        \n",
    "#         if (i != (NUM_BIAS_SIGMOID-1)): # no comma for last term\n",
    "#             # OPTIONAL: adds floating number as comment as reference\n",
    "#             dest_file.write(\",  // \" + str(flt_num) + \"\\n\")\n",
    "#         else:\n",
    "#             dest_file.write(\"   // \" + str(flt_num) + \"\\n\")\n",
    "    \n",
    "#     # finish off declarations\n",
    "#     dest_file.write(\"};\\nendpackage\")\n",
    "    \n",
    "    \n",
    "    \n",
    "#     #subprocess.call([\"sed\", 's/-//g', file_name]) # doesn't work\n",
    "#     dest_file.close()\n",
    "#     src_biases_file.close()\n",
    "#     src_weights_file.close()\n",
    "    \n",
    "#     # replace negative '-' character\n",
    "#     remove_negs(tmp_file, file_name)\n",
    "\n",
    "\n",
    "# # =+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=\n",
    "\n",
    "# # Set width and fractional bits you want to generate\n",
    "# width = 10\n",
    "# nfrac = 5\n",
    "\n",
    "# # run function\n",
    "# # generate_sigmoid_pkg_file(width, nfrac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb01418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# generate sigmoid bram\n",
    "# =======================================================\n",
    "\n",
    "\n",
    "def generate_sigmoid_bram_bin_file(width, nfrac, table_size_pow, prec):\n",
    "    file = open(\"./sigmoid_BRAM_vals.txt\", 'w')\n",
    "    \n",
    "    # number of table entries\n",
    "    N_TABLE = 2**table_size_pow\n",
    "\n",
    "    index = np.arange(-8, 8, 16.0/N_TABLE)\n",
    "\n",
    "    for n in index:\n",
    "        file.write(str(sigmoid(n)))\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    # =================================================================\n",
    "    # now convert into binary\n",
    "    div = (2**prec)*1.0\n",
    "\n",
    "    src_file = open(\"sigmoid_BRAM_vals.txt\", 'r')\n",
    "    \n",
    "    file_name = \"./binaries/sigmoid_BRAM_binaries\" + \"/memw\" + str(prec) + \"_size\" + str(int(N_TABLE)) + \"_sigmoidBRAM.mem\"\n",
    "    tmp_file = \"./binaries/sigmoid_BRAM_binaries\" + \"/tmp.mem\"\n",
    "    dest_file = open(tmp_file, 'w')\n",
    "\n",
    "    for i in range(int(N_TABLE)):\n",
    "        x = round(float(src_file.readline())*div // 1)\n",
    "    \n",
    "        if (x < 0):\n",
    "            dest_file.write(format(flip_bits(x, width), '0'+ str(prec) + 'b'))\n",
    "            dest_file.write(\"\\n\")\n",
    "        else:\n",
    "            dest_file.write(format(x, '0'+ str(prec) + 'b'))\n",
    "            dest_file.write(\"\\n\")\n",
    "        \n",
    "    dest_file.close()\n",
    "    src_file.close()\n",
    "    \n",
    "    # replace negative '-' character\n",
    "    remove_negs(tmp_file, file_name)\n",
    "\n",
    "\n",
    "# =+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=\n",
    "\n",
    "# Set width and fractional bits you want to generate\n",
    "width = 10\n",
    "nfrac = 5\n",
    "\n",
    "# run function\n",
    "generate_sigmoid_bram_bin_file(width, nfrac, 10, 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ca4672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# generate tanh bram (input range from 0 to 8, since tanh is symmetric around 0)\n",
    "# =======================================================\n",
    "def generate_tanh_bram_bin_file(width, nfrac, table_size_pow, prec):\n",
    "    file = open(\"./tanh_BRAM_vals.txt\", 'w')\n",
    "    \n",
    "    # number of table entries\n",
    "    N_TABLE = 2**table_size_pow\n",
    "\n",
    "    # initialize array with zeros\n",
    "    index = np.arange(0, 8, 8.0/N_TABLE)\n",
    "\n",
    "    for n in index:\n",
    "        file.write(str(np.tanh(n)))\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    # =================================================================\n",
    "    # now convert into binary\n",
    "    div = (2**prec)*1.0\n",
    "\n",
    "    src_file = open(\"tanh_BRAM_vals.txt\", 'r')\n",
    "    \n",
    "    file_name = \"./binaries/tanh_BRAM_binaries\" + \"/memw\" + str(prec) + \"_size\" + str(int(N_TABLE)) + \"_tanhBRAM.mem\"\n",
    "    dest_file = open(file_name, 'w')\n",
    "\n",
    "    for i in range(int(N_TABLE)):\n",
    "        x = round(float(src_file.readline())*div // 1)\n",
    "    \n",
    "        if (x < 0):\n",
    "            dest_file.write(format(flip_bits(x, width), '0'+ str(prec) + 'b'))\n",
    "            dest_file.write(\"\\n\")\n",
    "        else:\n",
    "            dest_file.write(format(x, '0'+ str(prec) + 'b'))\n",
    "            dest_file.write(\"\\n\")\n",
    "        \n",
    "    dest_file.close()\n",
    "    src_file.close()\n",
    "\n",
    "generate_tanh_bram_bin_file(17, 10, 9, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb4087d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================\n",
    "# ===============================================================================================\n",
    "# ===============================================================================================\n",
    "# ==============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a1e663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # generate specific set or write a simple for loop to generate multiple sets of files\n",
    "\n",
    "# width = 17              # width of numbers\n",
    "# nfrac = 10              # number of fractional bits\n",
    "# table_size_pow = 10     # BRAM size (2**table_size_pow)\n",
    "# prec = 10               # BRAM precision\n",
    "\n",
    "# # generate_input_bin_file(width, nfrac)\n",
    "# # generate_relu_pkg_file(width, nfrac)\n",
    "# # generate_sigmoid_pkg_file(width, nfrac)\n",
    "# # generate_sigmoid_bram_bin_file(width, nfrac, table_size_pow, prec)\n",
    "\n",
    "# # generate set of files for bit width 4-32\n",
    "# for i in range(4,33):\n",
    "#     width = i\n",
    "#     nfrac = (i+1) // 2\n",
    "    \n",
    "#     # generate_input_bin_file(width, nfrac)\n",
    "#     generate_relu_pkg_file(width, nfrac)\n",
    "#     generate_sigmoid_pkg_file(width, nfrac)\n",
    "    \n",
    "# generate_sigmoid_bram_bin_file(width, nfrac, table_size_pow, prec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c4fe69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls4ml-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
