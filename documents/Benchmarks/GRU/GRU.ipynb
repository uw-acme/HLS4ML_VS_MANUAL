{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 14:41:36.887160: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-21 14:41:36.994341: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-02-21 14:41:36.994356: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'wrapt' has no attribute 'ObjectProxy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN/model_toptag_gru.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml/lib/python3.10/site-packages/tensorflow/__init__.py:37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml/lib/python3.10/site-packages/tensorflow/python/__init__.py:42\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml/lib/python3.10/site-packages/tensorflow/python/data/__init__.py:21\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml/lib/python3.10/site-packages/tensorflow/python/data/experimental/__init__.py:96\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml/lib/python3.10/site-packages/tensorflow/python/data/experimental/service/__init__.py:419\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml/lib/python3.10/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_service_pb2\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml/lib/python3.10/site-packages/tensorflow/python/data/experimental/ops/compression_ops.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompress\u001b[39m(element):\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:22\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwrapt\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py:34\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"## Functions for working with arbitrarily nested sequences of elements.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mNOTE(mrry): This fork of the `tensorflow.python.util.nest` module\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m   arrays.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m _sparse_tensor\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml/lib/python3.10/site-packages/tensorflow/python/framework/sparse_tensor.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml/lib/python3.10/site-packages/tensorflow/python/framework/composite_tensor.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__internal__.CompositeTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCompositeTensor\u001b[39;00m(metaclass\u001b[38;5;241m=\u001b[39mabc\u001b[38;5;241m.\u001b[39mABCMeta):\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml/lib/python3.10/site-packages/tensorflow/python/util/nest.py:1739\u001b[0m\n\u001b[1;32m   1737\u001b[0m _pywrap_utils\u001b[38;5;241m.\u001b[39mRegisterType(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence\u001b[39m\u001b[38;5;124m\"\u001b[39m, _collections_abc\u001b[38;5;241m.\u001b[39mSequence)\n\u001b[1;32m   1738\u001b[0m _pywrap_utils\u001b[38;5;241m.\u001b[39mRegisterType(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMappingView\u001b[39m\u001b[38;5;124m\"\u001b[39m, _collections_abc\u001b[38;5;241m.\u001b[39mMappingView)\n\u001b[0;32m-> 1739\u001b[0m _pywrap_utils\u001b[38;5;241m.\u001b[39mRegisterType(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjectProxy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43m_wrapt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mObjectProxy\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'wrapt' has no attribute 'ObjectProxy'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('RNN/model_toptag_gru.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (GRU)                (None, 5)                 195       \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 5)                 30        \n",
      "                                                                 \n",
      " output_sigmoid (Dense)      (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 231\n",
      "Trainable params: 231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiuyal2/miniconda3/envs/hls4ml/lib/python3.10/site-packages/hls4ml/converters/__init__.py:27: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import os\n",
    "os.environ['PATH'] = '/opt/Xilinx/Vivado/2019.2/bin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: layer1_input, layer type: InputLayer, input shapes: [[None, 20, 6]], output shape: [None, 20, 6]\n",
      "Layer name: layer1, layer type: GRU, input shapes: [[None, 20, 6]], output shape: [None, 5]\n",
      "Layer name: layer2, layer type: Dense, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "Layer name: output_sigmoid, layer type: Dense, input shapes: [[None, 5]], output shape: [None, 1]\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: layer1_input, layer type: InputLayer, input shapes: [[None, 20, 6]], output shape: [None, 20, 6]\n",
      "Layer name: layer1, layer type: GRU, input shapes: [[None, 20, 6]], output shape: [None, 5]\n",
      "Layer name: layer2, layer type: Dense, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "Layer name: output_sigmoid, layer type: Dense, input shapes: [[None, 5]], output shape: [None, 1]\n",
      "Creating HLS model\n",
      "WARNING: Changing pipeline style to \"dataflow\".\n"
     ]
    }
   ],
   "source": [
    "config = hls4ml.utils.config_from_keras_model(model, granularity='model', default_precision='ap_fixed<18,8>')\n",
    "config['Model']['ReuseFactor']=1\n",
    "config['Model']['Strategy']='Resource'\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(model,\n",
    "                                                       hls_config=config,\n",
    "                                                       output_dir='model_1/hls4ml_prj',\n",
    "                                                       part='r xcku115-flvb2104-2-i'\n",
    "                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)\n",
      "  **** SW Build 2708876 on Wed Nov  6 21:39:14 MST 2019\n",
      "  **** IP Build 2700528 on Thu Nov  7 00:09:20 MST 2019\n",
      "    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source /tools/Xilinx/Vivado/2019.2/scripts/vivado_hls/hls.tcl -notrace\n",
      "INFO: [HLS 200-10] Running '/tools/Xilinx/Vivado/2019.2/bin/unwrapped/lnx64.o/vivado_hls'\n",
      "INFO: [HLS 200-10] For user 'jiuyal2' on host 'Duo16.' (Linux_x86_64 version 5.15.146.1-microsoft-standard-WSL2) on Wed Feb 21 03:46:42 PST 2024\n",
      "INFO: [HLS 200-10] On os Ubuntu 18.04.6 LTS\n",
      "INFO: [HLS 200-10] In directory '/home/jiuyal2/HLS4ML_VS_MANUAL/documents/Benchmarks/GRU/model_1/hls4ml_prj'\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-10] Opening project '/home/jiuyal2/HLS4ML_VS_MANUAL/documents/Benchmarks/GRU/model_1/hls4ml_prj/myproject_prj'.\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'firmware/weights' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'tb_data' to the project\n",
      "INFO: [HLS 200-10] Opening solution '/home/jiuyal2/HLS4ML_VS_MANUAL/documents/Benchmarks/GRU/model_1/hls4ml_prj/myproject_prj/solution1'.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 5ns.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with an uncertainty of 0.625ns.\n",
      "INFO: [HLS 200-10] Setting target device to 'xcvu13p-flga2577-2-e'\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 80.\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 80.\n",
      "***** C/RTL SYNTHESIS *****\n",
      "INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject.cpp' ... \n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:41:72\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:41:76\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:41:81\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:41:85\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:45:67\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:45:71\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:53:67\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:53:71\n",
      "WARNING: [HLS 200-471] Dataflow form checks found 8 issue(s) in file firmware/myproject.cpp\n",
      "INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:15 ; elapsed = 00:00:16 . Memory (MB): peak = 959.211 ; gain = 526.004 ; free physical = 11556 ; free virtual = 33411\n",
      "INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:15 ; elapsed = 00:00:16 . Memory (MB): peak = 959.211 ; gain = 526.004 ; free physical = 11556 ; free virtual = 33411\n",
      "INFO: [HLS 200-10] Starting code transformations ...\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccum' (firmware/nnet_utils/nnet_dense_resource.h:37) in function 'void nnet::dense_resource_rf_leq_nin<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>(FORWARD_REFERENCE*, FORWARD_REFERENCE*, FORWARD_REFERENCE::weight_t*, FORWARD_REFERENCE::bias_t*)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_resource.h:77) in function 'void nnet::dense_resource_rf_leq_nin<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>(FORWARD_REFERENCE*, FORWARD_REFERENCE*, FORWARD_REFERENCE::weight_t*, FORWARD_REFERENCE::bias_t*)' completely with a factor of 1.\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_resource_rf_leq_nin<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_1>' (firmware/nnet_utils/nnet_dense_resource.h:56).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_resource_rf_leq_nin<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_2>' (firmware/nnet_utils/nnet_dense_resource.h:56).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_resource_rf_leq_nin<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' (firmware/nnet_utils/nnet_dense_resource.h:56).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_resource_rf_leq_nin<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' (firmware/nnet_utils/nnet_dense_resource.h:56).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource_rf_leq_nin<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_1>' into 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_1>' (firmware/nnet_utils/nnet_dense_resource.h:253).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::cast<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_1>' into 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_1>' (firmware/nnet_utils/nnet_dense_resource.h:79->firmware/nnet_utils/nnet_dense_resource.h:253).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_1>' into 'nnet::gru_static<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_recurrent.h:426).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource_rf_leq_nin<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_2>' into 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_2>' (firmware/nnet_utils/nnet_dense_resource.h:253).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::cast<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_2>' into 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_2>' (firmware/nnet_utils/nnet_dense_resource.h:79->firmware/nnet_utils/nnet_dense_resource.h:253).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_2>' into 'nnet::gru_static<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_recurrent.h:427).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource_rf_leq_nin<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' into 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' (firmware/nnet_utils/nnet_dense_resource.h:253).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::cast<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' into 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' (firmware/nnet_utils/nnet_dense_resource.h:79->firmware/nnet_utils/nnet_dense_resource.h:253).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' into 'myproject' (firmware/myproject.cpp:45).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource_rf_leq_nin<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' into 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' (firmware/nnet_utils/nnet_dense_resource.h:253).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::cast<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' into 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' (firmware/nnet_utils/nnet_dense_resource.h:79->firmware/nnet_utils/nnet_dense_resource.h:253).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' into 'myproject' (firmware/myproject.cpp:53).\n",
      "INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:19 ; elapsed = 00:00:21 . Memory (MB): peak = 965.844 ; gain = 532.637 ; free physical = 11348 ; free virtual = 33228\n",
      "INFO: [HLS 200-10] Checking synthesizability ...\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::activation::sigmoid<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, sigmoid_config2_recr>::activation' into 'nnet::gru_static<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_recurrent.h:439) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::activation::tanh<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, tanh_config2>::activation' into 'nnet::gru_static<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_recurrent.h:458) automatically.\n",
      "INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:20 ; elapsed = 00:00:21 . Memory (MB): peak = 965.844 ; gain = 532.637 ; free physical = 11339 ; free virtual = 33220\n",
      "WARNING: [XFORM 203-505] Ignore pipeline pragma in Loop whose tripcount is only 1 (firmware/nnet_utils/nnet_dense_resource.h:44) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>'.\n",
      "WARNING: [XFORM 203-505] Ignore pipeline pragma in Loop whose tripcount is only 1 (firmware/nnet_utils/nnet_dense_resource.h:44) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>'.\n",
      "WARNING: [XFORM 203-505] Ignore pipeline pragma in Loop whose tripcount is only 1 (firmware/nnet_utils/nnet_dense_resource.h:44) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_2>'.\n",
      "WARNING: [XFORM 203-505] Ignore pipeline pragma in Loop whose tripcount is only 1 (firmware/nnet_utils/nnet_dense_resource.h:44) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_1>'.\n",
      "INFO: [XFORM 203-502] Unrolling small iteration loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:43) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' automatically.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::relu<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, relu_config4>' (firmware/nnet_utils/nnet_activation.h:40:43).\n",
      "INFO: [XFORM 203-502] Unrolling small iteration loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:43) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' automatically.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::tanh<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, tanh_config2>' (firmware/nnet_utils/nnet_activation.h:427:43).\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::sigmoid<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, sigmoid_config2_recr>' (firmware/nnet_utils/nnet_activation.h:109:43).\n",
      "INFO: [XFORM 203-502] Unrolling small iteration loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:43) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_2>' automatically.\n",
      "INFO: [XFORM 203-502] Unrolling small iteration loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:43) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_1>' automatically.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:43) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_dense_resource.h:52) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_activation.h:43) in function 'nnet::relu<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, relu_config4>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccum' (firmware/nnet_utils/nnet_dense_resource.h:37) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:43) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_dense_resource.h:52) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 25.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_resource.h:77) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_recurrent.h:483) in function 'nnet::gru_stack<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (firmware/nnet_utils/nnet_recurrent.h:488) in function 'nnet::gru_stack<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 6.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-3' (firmware/nnet_utils/nnet_recurrent.h:504) in function 'nnet::gru_stack<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_recurrent.h:420) in function 'nnet::gru_static<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-2' (firmware/nnet_utils/nnet_recurrent.h:432) in function 'nnet::gru_static<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-3' (firmware/nnet_utils/nnet_recurrent.h:445) in function 'nnet::gru_static<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-4' (firmware/nnet_utils/nnet_recurrent.h:451) in function 'nnet::gru_static<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-5' (firmware/nnet_utils/nnet_recurrent.h:462) in function 'nnet::gru_static<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_activation.h:432) in function 'nnet::tanh<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, tanh_config2>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_activation.h:114) in function 'nnet::sigmoid<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, sigmoid_config2_recr>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccum' (firmware/nnet_utils/nnet_dense_resource.h:37) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_2>' completely with a factor of 15.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:43) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_2>' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_dense_resource.h:52) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_2>' completely with a factor of 75.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_resource.h:77) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_2>' completely with a factor of 15.\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccum' (firmware/nnet_utils/nnet_dense_resource.h:37) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_1>' completely with a factor of 15.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:43) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_1>' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_dense_resource.h:52) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_1>' completely with a factor of 90.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_resource.h:77) in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_1>' completely with a factor of 15.\n",
      "INFO: [XFORM 203-131] Reshaping array 'layer1_input.V' (firmware/myproject.cpp:7) in dimension 1 completely.\n",
      "INFO: [XFORM 203-131] Reshaping array 'w5.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-131] Reshaping array 'w3.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-131] Reshaping array 'wr2.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-131] Reshaping array 'w2.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer6_out.V' (firmware/myproject.cpp:8) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer2_out.V' (firmware/myproject.cpp:39) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer3_out.V' (firmware/myproject.cpp:43) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer4_out.V' (firmware/myproject.cpp:47) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer5_out.V' (firmware/myproject.cpp:51) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'h_state.V114'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'data_in.V' (firmware/nnet_utils/nnet_recurrent.h:477) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b5.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_resource.h:33) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b3.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_resource.h:33) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'h_state.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmpres'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmpres_state_zr'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmpres_state_h.V' (firmware/nnet_utils/nnet_recurrent.h:403) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmpres_zr'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmpres_h'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'inputacc_zr.V' (firmware/nnet_utils/nnet_recurrent.h:406) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'inputacc_h.V' (firmware/nnet_utils/nnet_recurrent.h:407) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'br2.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_resource.h:33) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b2.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_resource.h:33) in dimension 1 completely.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::activation::sigmoid<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, sigmoid_config2_recr>::activation' into 'nnet::gru_static<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_recurrent.h:439) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::activation::tanh<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, tanh_config2>::activation' into 'nnet::gru_static<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_recurrent.h:458) automatically.\n",
      "INFO: [XFORM 203-712] Applying dataflow to function 'myproject', detected/extracted 5 process function(s): \n",
      "\t 'nnet::gru_stack<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>'\n",
      "\t 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>'\n",
      "\t 'nnet::relu<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, relu_config4>'\n",
      "\t 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>'\n",
      "\t 'nnet::sigmoid<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, sigmoid_config6>'.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation.h:413:74) to (firmware/nnet_utils/nnet_activation.h:442:1) in function 'nnet::tanh<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, tanh_config2>'... converting 11 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation.h:95:21) to (firmware/nnet_utils/nnet_activation.h:123:1) in function 'nnet::sigmoid<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, sigmoid_config6>'... converting 3 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation.h:95:21) to (firmware/nnet_utils/nnet_activation.h:123:1) in function 'nnet::sigmoid<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, sigmoid_config2_recr>'... converting 21 basic blocks.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' (firmware/nnet_utils/nnet_dense_resource.h:44:1)...5 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' (firmware/nnet_utils/nnet_dense_resource.h:44:1)...25 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_2>' (firmware/nnet_utils/nnet_dense_resource.h:44:1)...73 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_1>' (firmware/nnet_utils/nnet_dense_resource.h:44:17)...88 expression(s) balanced.\n",
      "INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:21 ; elapsed = 00:00:23 . Memory (MB): peak = 1151.211 ; gain = 718.004 ; free physical = 11246 ; free virtual = 33136\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::tanh<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, tanh_config2>' to 'tanh<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, tanh_config2>' (firmware/nnet_utils/nnet_activation.h:413)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::sigmoid<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, sigmoid_config6>' to 'sigmoid<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, sigmoid_config6>' (firmware/nnet_utils/nnet_activation.h:95)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::sigmoid<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, sigmoid_config2_recr>' to 'sigmoid<ap_fixed,ap_fixed<18,8,5,3,0>,sigmoid_config2_recr>' (firmware/nnet_utils/nnet_activation.h:109:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::relu<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, relu_config4>' to 'relu<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, relu_config4>' (firmware/nnet_utils/nnet_activation.h:39)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::gru_static<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' to 'gru_static<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config2>' (firmware/nnet_utils/nnet_recurrent.h:393)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::gru_stack<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' to 'gru_stack<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config2>' (firmware/nnet_utils/nnet_recurrent.h:470)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' to 'dense_resource<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config5>' (firmware/nnet_utils/nnet_dense_resource.h:246)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' to 'dense_resource<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config3>' (firmware/nnet_utils/nnet_dense_resource.h:246)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_2>' to 'dense_resource<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config2_2>' (firmware/nnet_utils/nnet_dense_resource.h:246)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_resource<ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<18, 8, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_1>' to 'dense_resource<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config2_1>' (firmware/nnet_utils/nnet_dense_resource.h:246)\n",
      "WARNING: [XFORM 203-532] Ignored the rewind option for Function 'dense_resource<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config5>' (firmware/nnet_utils/nnet_dense_resource.h:246) as the option is not applicable to function pipelining.\n",
      "WARNING: [XFORM 203-532] Ignored the rewind option for Function 'dense_resource<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config3>' (firmware/nnet_utils/nnet_dense_resource.h:246) as the option is not applicable to function pipelining.\n",
      "WARNING: [XFORM 203-532] Ignored the rewind option for Function 'dense_resource<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config2_2>' (firmware/nnet_utils/nnet_dense_resource.h:246) as the option is not applicable to function pipelining.\n",
      "WARNING: [XFORM 203-532] Ignored the rewind option for Function 'dense_resource<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config2_1>' (firmware/nnet_utils/nnet_dense_resource.h:246) as the option is not applicable to function pipelining.\n",
      "INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:22 ; elapsed = 00:00:24 . Memory (MB): peak = 1152.363 ; gain = 719.156 ; free physical = 11229 ; free virtual = 33123\n",
      "INFO: [HLS 200-10] Starting hardware synthesis ...\n",
      "INFO: [HLS 200-10] Synthesizing 'myproject' ...\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_resource<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config2_1>' to 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_1_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_resource<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config2_2>' to 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'sigmoid<ap_fixed,ap_fixed<18,8,5,3,0>,sigmoid_config2_recr>' to 'sigmoid_ap_fixed_ap_fixed_18_8_5_3_0_sigmoid_config2_recr_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'tanh<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, tanh_config2>' to 'tanh_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_tanh_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'gru_static<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config2>' to 'gru_static_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'gru_stack<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config2>' to 'gru_stack_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_resource<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config3>' to 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config3_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, relu_config4>' to 'relu_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_relu_config4_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_resource<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, config5>' to 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config5_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'sigmoid<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, sigmoid_config6>' to 'sigmoid_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_sigmoid_config6_s'.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_1_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 23.9 seconds; current allocated memory: 413.364 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 414.954 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.39 seconds; current allocated memory: 415.986 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.18 seconds; current allocated memory: 417.163 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'sigmoid_ap_fixed_ap_fixed_18_8_5_3_0_sigmoid_config2_recr_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'sigmoid<ap_fixed,ap_fixed<18,8,5,3,0>,sigmoid_config2_recr>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.29 seconds; current allocated memory: 418.036 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 419.098 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'tanh_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_tanh_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'tanh<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, tanh_config2>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.21 seconds; current allocated memory: 419.637 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.07 seconds; current allocated memory: 420.206 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'gru_static_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 420.753 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 421.632 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'gru_stack_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 422.206 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 422.564 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config3_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.4 seconds; current allocated memory: 423.200 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.06 seconds; current allocated memory: 423.618 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_relu_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'relu<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, relu_config4>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 423.734 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.02 seconds; current allocated memory: 423.871 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.04 seconds; current allocated memory: 423.980 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.02 seconds; current allocated memory: 424.101 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'sigmoid_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_sigmoid_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'sigmoid<ap_fixed<18, 8, 5, 3, 0>, ap_fixed<18, 8, 5, 3, 0>, sigmoid_config6>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.04 seconds; current allocated memory: 424.202 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.03 seconds; current allocated memory: 424.350 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'myproject' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.03 seconds; current allocated memory: 424.492 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.49 seconds; current allocated memory: 425.010 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_1_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_10ns_28_1_1': 8 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_10s_28_1_1': 11 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_11ns_28_1_1': 7 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_11s_28_1_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_12ns_28_1_1': 5 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_12s_28_1_1': 3 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_13s_28_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_6ns_24_1_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_7ns_25_1_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_7s_25_1_1': 4 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_8ns_26_1_1': 4 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_8s_26_1_1': 5 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_9ns_27_1_1': 5 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_9s_27_1_1': 9 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_1_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.54 seconds; current allocated memory: 428.905 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_10ns_28_1_1': 7 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_10s_28_1_1': 4 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_11ns_28_1_1': 20 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_11s_28_1_1': 10 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_12ns_28_1_1': 7 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_12s_28_1_1': 5 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_13ns_28_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_13s_28_1_1': 4 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_14s_28_1_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_7ns_25_1_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_8s_26_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_9ns_27_1_1': 3 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_9s_27_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_2_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.65 seconds; current allocated memory: 438.336 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'sigmoid_ap_fixed_ap_fixed_18_8_5_3_0_sigmoid_config2_recr_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'sigmoid_ap_fixed_ap_fixed_18_8_5_3_0_sigmoid_config2_recr_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.55 seconds; current allocated memory: 444.882 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'tanh_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_tanh_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'tanh_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_tanh_config2_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.54 seconds; current allocated memory: 449.537 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'gru_static_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "WARNING: [RTGEN 206-101] Register 'h_state_V_0' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'h_state_V_1' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'h_state_V_2' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'h_state_V_3' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'h_state_V_4' is power-on initialization.\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mac_muladd_18s_18s_28s_28_1_1': 5 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_18s_28_1_1': 5 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_19s_18s_28_1_1': 5 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'gru_static_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.39 seconds; current allocated memory: 453.678 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'gru_stack_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "WARNING: [RTGEN 206-101] Register 'h_state_V114_0' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'h_state_V114_1' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'h_state_V114_2' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'h_state_V114_3' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'h_state_V114_4' is power-on initialization.\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'gru_stack_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config2_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.69 seconds; current allocated memory: 457.098 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config3_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_10ns_28_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_10s_28_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_11ns_28_1_1': 3 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_11s_28_1_1': 5 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_12ns_28_1_1': 6 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_12s_28_1_1': 3 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_13ns_28_1_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_13s_28_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_9ns_27_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_18s_9s_27_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config3_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.59 seconds; current allocated memory: 459.546 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'relu_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_relu_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'relu_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_relu_config4_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.35 seconds; current allocated memory: 461.505 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_17ns_12ns_28_1_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_17ns_12s_28_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_mul_mul_17ns_13s_28_1_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_resource_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_config5_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.28 seconds; current allocated memory: 462.256 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'sigmoid_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_sigmoid_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'sigmoid_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_sigmoid_config6_s_sigmoid_table1' to 'sigmoid_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_sigmoid_config6_s_sigmoid_tabbkb' due to the length limit 80\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'sigmoid_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_sigmoid_config6_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.27 seconds; current allocated memory: 463.066 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'myproject' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer1_input_V' to 'ap_vld'.\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer6_out_0_V' to 'ap_vld'.\n",
      "INFO: [RTGEN 206-500] Setting interface mode on function 'myproject' to 'ap_ctrl_hs'.\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'myproject'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.29 seconds; current allocated memory: 464.332 MB.\n",
      "INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were satisfied.\n",
      "INFO: [HLS 200-789] **** Estimated Fmax: 234.03 MHz\n",
      "INFO: [RTMG 210-279] Implementing memory 'sigmoid_ap_fixed_ap_fixed_18_8_5_3_0_sigmoid_config2_recr_s_sigmoid_table4_rom' using block ROMs.\n",
      "INFO: [RTMG 210-279] Implementing memory 'tanh_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_tanh_config2_s_tanh_table2_rom' using block ROMs.\n",
      "INFO: [RTMG 210-279] Implementing memory 'sigmoid_ap_fixed_18_8_5_3_0_ap_fixed_18_8_5_3_0_sigmoid_config6_s_sigmoid_tabbkb_rom' using auto ROMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_0_V_U(fifo_w18_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_1_V_U(fifo_w18_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_2_V_U(fifo_w18_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_3_V_U(fifo_w18_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_4_V_U(fifo_w18_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_0_V_U(fifo_w18_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_1_V_U(fifo_w18_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_2_V_U(fifo_w18_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_3_V_U(fifo_w18_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_4_V_U(fifo_w18_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_0_V_U(fifo_w17_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_1_V_U(fifo_w17_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_2_V_U(fifo_w17_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_3_V_U(fifo_w17_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_4_V_U(fifo_w17_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_0_V_U(fifo_w18_d2_A)' using Shift Registers.\n",
      "INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:33 ; elapsed = 00:00:36 . Memory (MB): peak = 1279.211 ; gain = 846.004 ; free physical = 11106 ; free virtual = 33027\n",
      "INFO: [VHDL 208-304] Generating VHDL RTL for myproject.\n",
      "INFO: [VLOG 209-307] Generating Verilog RTL for myproject.\n",
      "***** C/RTL SYNTHESIS COMPLETED IN 0h0m34s *****\n",
      "***** VIVADO SYNTHESIS *****\n",
      "\n",
      "****** Vivado v2019.2 (64-bit)\n",
      "  **** SW Build 2708876 on Wed Nov  6 21:39:14 MST 2019\n",
      "  **** IP Build 2700528 on Thu Nov  7 00:09:20 MST 2019\n",
      "    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source vivado_synth.tcl\n",
      "# set tcldir [file dirname [info script]]\n",
      "# source [file join $tcldir project.tcl]\n",
      "## variable project_name\n",
      "## set project_name \"myproject\"\n",
      "## variable backend\n",
      "## set backend \"vivado\"\n",
      "## variable part\n",
      "## set part \"xcvu13p-flga2577-2-e\"\n",
      "## variable clock_period\n",
      "## set clock_period 5\n",
      "## variable clock_uncertainty\n",
      "## set clock_uncertainty 12.5%\n",
      "## variable version\n",
      "## set version \"1.0.0\"\n",
      "# add_files ${project_name}_prj/solution1/syn/vhdl\n",
      "# synth_design -top ${project_name} -part $part\n",
      "Command: synth_design -top myproject -part xcvu13p-flga2577-2-e\n",
      "Starting synth_design\n",
      "Attempting to get a license for feature 'Synthesis' and/or device 'xcvu13p'\n",
      "WARNING: [Common 17-348] Failed to get the license for feature 'Synthesis' and/or device 'xcvu13p'. Explanation: The license feature Synthesis could not be found.\n",
      "Resolution: Check the status of your licenses in the Vivado License Manager. For debug help search Xilinx Support for \"Licensing FAQ\". \n",
      "0 Infos, 1 Warnings, 0 Critical Warnings and 1 Errors encountered.\n",
      "synth_design failed\n",
      "INFO: [Common 17-206] Exiting Vivado at Wed Feb 21 03:47:39 2024...\n",
      "ERROR: [Common 17-345] A valid license was not found for feature 'Synthesis' and/or device 'xcvu13p'. Please run the Vivado License Manager for assistance in determining\n",
      "which features and devices are licensed for your system.\n",
      "Resolution: Check the status of your licenses in the Vivado License Manager. For debug help search Xilinx Support for \"Licensing FAQ\". If you are using a license server, verify that the license server is up and running a version of the xilinx daemon that is compatible with the version of Xilinx software that you are using. Please note that Vivado 2017.3 and later requires upgrading your license server tools to the Flex 11.14.1 tools. Please confirm with your license admin that the correct version of the license server tools are installed.\n",
      "    while executing\n",
      "\"exec vivado -mode batch -source vivado_synth.tcl >@ stdout\"\n",
      "    invoked from within\n",
      "\"if {$opt(vsynth)} {\n",
      "    puts \"***** VIVADO SYNTHESIS *****\"\n",
      "    if {[file exist ${project_name}_prj/solution1/syn/vhdl]} {\n",
      "        set time_start [clo...\"\n",
      "    (file \"build_prj.tcl\" line 237)\n",
      "    invoked from within\n",
      "\"source build_prj.tcl\"\n",
      "    (\"uplevel\" body line 1)\n",
      "    invoked from within\n",
      "\"uplevel \\#0 [list source $arg] \"\n",
      "\n",
      "INFO: [HLS 200-112] Total elapsed time: 66.56 seconds; peak allocated memory: 464.332 MB.\n",
      "INFO: [Common 17-206] Exiting vivado_hls at Wed Feb 21 03:47:49 2024...\n",
      "Vivado synthesis report not found.\n",
      "Cosim report not found.\n",
      "Timing report not found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CSynthesisReport': {'TargetClockPeriod': '5.00',\n",
       "  'EstimatedClockPeriod': '4.273',\n",
       "  'BestLatency': '226',\n",
       "  'WorstLatency': '226',\n",
       "  'IntervalMin': '222',\n",
       "  'IntervalMax': '222',\n",
       "  'BRAM_18K': '9',\n",
       "  'DSP': '179',\n",
       "  'FF': '2950',\n",
       "  'LUT': '21224',\n",
       "  'URAM': '0',\n",
       "  'AvailableBRAM_18K': '5376',\n",
       "  'AvailableDSP': '12288',\n",
       "  'AvailableFF': '3456000',\n",
       "  'AvailableLUT': '1728000',\n",
       "  'AvailableURAM': '1280'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model.build(csim=False, synth=True, vsynth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls4ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
